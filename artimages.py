# -*- coding: utf-8 -*-
"""ArtImages.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HDiqONVWC7wguxhL8UZZRdwlI5Z6eHWw

# ART IMAGES

## Pre-código
Primero  conectamos el Drive al Collaboratory
"""

from google.colab import drive
drive.mount('/content/drive')

"""Comprobamos que estamos usando la GPU"""

import tensorflow as tf
tf.test.gpu_device_name()

"""Comprobamos que podemos acceder al drive visualizando una imagen del dataset"""

!ls "/content/drive/My Drive/Colab Notebooks/datasets"

from matplotlib.pyplot import imshow
import numpy as np
from PIL import Image

# %matplotlib inline
pil_im = Image.open('/content/drive/My Drive/Colab Notebooks/datasets/Art-Dataset/train/drawings/3457_mainfoto_05.jpg', 'r')
imshow(np.asarray(pil_im))

"""## Código

### Datos
"""

from keras.applications import vgg16
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import keras
from keras.applications.vgg16 import preprocess_input, decode_predictions
import numpy as np
from time import time


# DATA SOURCE --------------------------------------------------

#Seleccionamos las carpetas de imágenes que usaremos para entrenar y para validar
train_data_dir = '/content/drive/My Drive/Colab Notebooks/datasets/Art-Dataset/train'
validation_data_dir = '/content/drive/My Drive/Colab Notebooks/datasets/Art-Dataset/validate'

train_datagen = ImageDataGenerator(rescale=1./255)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_data_dir,
        target_size=(200, 200),
        batch_size=20,
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        validation_data_dir,
        target_size=(200, 200),
        batch_size=20,
        class_mode='categorical')

"""### Red propia"""

# MODEL --------------------------------------------------

# Usaremos un modelo secuencial que es cuando las capas se ordenan secuencialmente
# desde el input hasta el output, tambien existe el modelo funcional, que es mas complejo
model = Sequential()
# Añadimos la primera capa convolutiva - nº kernels, size del kernel, funcion de
# activacion, informacion acerca de los datos. De aqui sale un volumen de 198,198,32
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=(200, 200, 3)))
# Como el volumes es muy grande, usamos el MaxPooling para poder acceder a la
# información más importante
model.add(MaxPooling2D(pool_size=(2, 2)))
# Añadimos otra capa convolutiva y otro MaxPooling
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
#Añadimos otra capa convolutiva y otro MaxPooling
model.add(Conv2D(96, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
# Hacemos un DropOut, que desactiva la actualizacion de pesos de ciertas neuronas 
# aleatoriamente para evitar el OverFitting 
model.add(Dropout(0.25))
# Aplicamos un Flatten que es un "aplanador", que convierte el tensor en un vector
model.add(Flatten())
# Metemos una capa densa - FullyConnected
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
# Metemos una ultima capa densa de 5 clases
model.add(Dense(5, activation='softmax'))

# - primero la función de pérdida, optimizador y las métricas, que en este caso
# comparan los casos con la validación
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

# TRAINING --------------------------------------------------

epochs = 20

# Entrenamos usando el fit_generator porque estamos usando generadores de imágenes 
# steps_per_epoch --> como al añadir virtualmente imagenes el dataset se hace 
# infinito, así que tenemos que poner un límite.
model.fit_generator(
        train_generator,
        steps_per_epoch=20,
        epochs=epochs, 
        validation_data=validation_generator,
        validation_steps=20,
)

"""### VGG16"""

from keras.applications import vgg16

# MODEL --------------------------------------------------
#Incluimos una red densa al fina, no especificamos pesos ni tensores, especificamos 
#los datos de entrada, no especificamos pooling y especificamos las clases finales
model = vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(200,200,3), pooling=None, classes=5)  
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

#Visualizamos el modelo
model.summary()

# TRAINING --------------------------------------------------

epochs = 20
#Entrenamos el modelo
vgg16=model.fit_generator(
        train_generator,
        steps_per_epoch=20,
        epochs=epochs, 
        validation_data=validation_generator,
        validation_steps=20,
)

"""###Gráfica VGG16"""

import matplotlib.pyplot as plt 

#Creamos las gráficas
plt.figure(0)  
plt.plot(vgg16.history['acc'],'r')  
plt.plot(vgg16.history['val_acc'],'g')  
plt.xticks(np.arange(0, 20, 2.0))  
plt.rcParams['figure.figsize'] = (8, 6)  
plt.xlabel("Num of Epochs")  
plt.ylabel("Accuracy")  
plt.title("Training vs Validation")  
plt.legend(['train','validation'])

plt.figure(1)  
plt.plot(vgg16.history['loss'],'r')  
plt.plot(vgg16.history['val_loss'],'g')  
plt.xticks(np.arange(0, 20, 2.0))  
plt.rcParams['figure.figsize'] = (8, 6)  
plt.xlabel("Epochs")  
plt.ylabel("Loss")  
plt.title("Training vs Validation")  
plt.legend(['train','validation'])

#Mostramos las gráficas
plt.show()